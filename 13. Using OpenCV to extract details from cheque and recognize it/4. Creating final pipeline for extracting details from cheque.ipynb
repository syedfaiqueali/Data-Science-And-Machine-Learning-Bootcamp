{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.compat.v1.saved_model import load, tag_constants\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALPHABETS = {\n",
    "    0:'A', 1:'B', 2:'C', 3:'D', 4:'E', 5:'F', 6:'G', 7:'H', 8:'I',9:'J',\n",
    "    10:'K', 11:'L', 12:'M', 13:'N', 14:'O', 15:'P', 16:'Q', 17:'R', 18:'S',\n",
    "    19:'T', 20:'U', 21:'V', 22:'W', 23:'X', 24: 'Y', 25:'Z'\n",
    "}\n",
    "\n",
    "SAMPLE_IMAGE = 'Image_Samples/Sample1.png'\n",
    "\n",
    "ARR_LEFT_SECTION_CONTOURS = []\n",
    "ARR_PAYEE_CONTOURS = []\n",
    "ARR_PAYEE_WORDS = []\n",
    "ARR_PAYEE_FIRST_NAME = []\n",
    "ARR_PAYEE_MIDDLE_NAME = []\n",
    "ARR_PAYEE_LAST_NAME = []\n",
    "\n",
    "ARR_RIGHT_SECTION_CONTOURS = []\n",
    "ARR_DATE_CONTOURS = []\n",
    "ARR_AMOUNT_CONTOURS = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_contour_with_least_area(contours):\n",
    "    '''\n",
    "    This function will calculate contours area and return the least one\n",
    "    Parameters:\n",
    "    contours: All contours hierarchy array\n",
    "    '''\n",
    "    \n",
    "    # Step1: Find areas of every contour\n",
    "    areas = []\n",
    "    for cnt in contours:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        # All areas appended in sequence\n",
    "        areas.append(int(area))\n",
    "        \n",
    "    # Step2: Find the contour index with the least area\n",
    "    least_area = areas[0]\n",
    "    index = 0\n",
    "    \n",
    "    for i in range(0, len(areas)):\n",
    "        if areas[i] <= least_area:\n",
    "            # Update least value\n",
    "            least_area = areas[i]\n",
    "            index = i\n",
    "            \n",
    "    # Step3: Return the least area contour index\n",
    "    return index\n",
    "\n",
    "def find_contour_with_greatest_area(contours):\n",
    "    '''\n",
    "    This function will calculate contours area and return the least one\n",
    "    Parameters:\n",
    "    contours: All contours hierarchy array\n",
    "    '''\n",
    "    \n",
    "    # Step1: Find areas of every contour\n",
    "    areas = []\n",
    "    for cnt in contours:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        # All areas appended in sequence\n",
    "        areas.append(int(area))\n",
    "        \n",
    "    # Step2: Find the contour index with the least area\n",
    "    greatest_area = areas[0]\n",
    "    index = 0\n",
    "    \n",
    "    for i in range(0, len(areas)):\n",
    "        if areas[i] >= greatest_area:\n",
    "            # Update least value\n",
    "            greatest_area = areas[i]\n",
    "            index = i\n",
    "            \n",
    "    # Step3: Return the least area contour index\n",
    "    return index, areas\n",
    "\n",
    "\n",
    "def draw_rectangle_on_img_contours_and_save_them(contours, image, arr_contours):\n",
    "    '''\n",
    "    This function will draw rectangles on image\n",
    "    Parameters:\n",
    "    contours : array\n",
    "    image: image\n",
    "    arr_contours: array in which cropped contours to be saved\n",
    "    '''\n",
    "    total_contours = len(contours)\n",
    "    rect_color = (0,0,0)\n",
    "    rect_stroke_width = 0\n",
    "    \n",
    "    for i in range(total_contours):\n",
    "        cnt = contours[i]\n",
    "        x,y,w,h = cv2.boundingRect(cnt)\n",
    "        image = cv2.rectangle(image, (x,y), (x+w,y+h), rect_color, rect_stroke_width)\n",
    "        \n",
    "        # Cropping individual contours and saving them as separate image\n",
    "        cropping_rectangles_and_saving_them(x,y,x+w,y+h,image,i,arr_contours)\n",
    "        \n",
    "    # To visualize all contours on image\n",
    "    #plt.imshow(image)\n",
    "    #plt.show()\n",
    "    \n",
    "    \n",
    "def cropping_rectangles_and_saving_them(left,upper,right,lower, image_name, cropped_image_name, arr_contours):\n",
    "    '''\n",
    "    This function will crop all the bounding rectangles from an image\n",
    "    Parameters:\n",
    "    left=x,upper=y,right=x+w,lower=y+h\n",
    "    image_name: original image\n",
    "    cropped_image_name: individual cropped images name\n",
    "    '''\n",
    "    # Opens image using PIL\n",
    "    im = Image.fromarray(image_name)\n",
    "\n",
    "    # Crop image from original image\n",
    "    box = (left,upper,right,lower)\n",
    "    cropped_image = im.crop(box)\n",
    "\n",
    "    # Appending cropped contours\n",
    "    arr_contours.append(cropped_image)\n",
    "    \n",
    "def remove_contours_beyond_desired_area_range(contours, desired_area):\n",
    "    '''\n",
    "    This function will return only those contours that lie into our desired area range\n",
    "    Parameters:\n",
    "    contours: All contours hierarchy array\n",
    "    '''\n",
    "\n",
    "    # Step1: Find areas of every contour\n",
    "    arr_cnts = []\n",
    "    for cnt in contours:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        if int(area) >= desired_area:\n",
    "            arr_cnts.append(cnt)\n",
    "\n",
    "    return arr_cnts\n",
    "\n",
    "\n",
    "def ret_x_cord_contour(contours):\n",
    "    '''\n",
    "    This func will get x-cord for contour\n",
    "    Parameters:\n",
    "    contours: Array containing all contours\n",
    "    '''\n",
    "    if int(cv2.contourArea(contours)) > 0:\n",
    "        cent_moment = cv2.moments(contours)\n",
    "        return cent_moment['m10']/cent_moment['m00']\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "def draw_rectangle_on_img_contours_and_croppping_them(contours, image, arr_contours):\n",
    "    '''\n",
    "    This function will draw rectangles on image\n",
    "    Parameters:\n",
    "    contours : array\n",
    "    image: image\n",
    "    arr_contours: array in which cropped contours to be saved\n",
    "    '''\n",
    "    total_contours = len(contours)\n",
    "    rect_color = (255,0,0)\n",
    "    rect_stroke_width = 2\n",
    "\n",
    "    new_img = image.copy()\n",
    "\n",
    "    for i in range(total_contours):\n",
    "        cnt = contours[i]\n",
    "        x,y,w,h = cv2.boundingRect(cnt)\n",
    "        image = cv2.rectangle(image, (x,y), (x+w,y+h), rect_color, rect_stroke_width)\n",
    "\n",
    "        # Step 5: Cropping individual contours and saving them in array\n",
    "        cropping_rectangles_and_saving_them(x,y,x+w,y+h,new_img,i,arr_contours)\n",
    "        \n",
    "        \n",
    "def get_all_childs_of_parent(parent, hierarchy):\n",
    "    '''\n",
    "    This function will return all the child of that contour\n",
    "    Parameters:\n",
    "    parent : Int value\n",
    "    hierarchy: contours hierarchy\n",
    "    '''\n",
    "    # Initialize\n",
    "    hier_len = hierarchy.shape[1] #Total contours\n",
    "    child_contours = {} #Empty Dict\n",
    "\n",
    "    for x in range(hier_len):\n",
    "        # To loop through whole hierarchy\n",
    "        next_contour, pre_contour, first_child, parent_contour = hierarchy[0][x]\n",
    "\n",
    "        # If desired parent found, so append it all childs\n",
    "        if parent == parent_contour:\n",
    "            child_contours[x] = hierarchy[0][x]\n",
    "\n",
    "    # return all the found contours\n",
    "    return child_contours\n",
    "\n",
    "\n",
    "def remove_extraneous_contours(index_to_keep, contours_dict):\n",
    "    '''\n",
    "    This function will remove extraneous contours from all child contours\n",
    "    Parameters:\n",
    "    index_to_keep : Array containing hierarchy values to keep\n",
    "    contours_dict: All child contours dict\n",
    "    '''\n",
    "    # Initialize an empty dict\n",
    "    final_dict = {}\n",
    "\n",
    "    # Loop through all contours child dict and search for index_to_keep keys\n",
    "    for x in index_to_keep:\n",
    "        final_dict[x] = contours_dict[x]\n",
    "\n",
    "    # Return only desired childs\n",
    "    return final_dict\n",
    "\n",
    "def remove_extraneous_contours_childs(contours,contours_dict):\n",
    "    '''\n",
    "    This function will remove extraneous contours from all contours\n",
    "    Parameters:\n",
    "    contours: Array containing all contours\n",
    "    contours_dict: All child contours dict which we want to keep\n",
    "    '''\n",
    "    arr_keys = []\n",
    "    new_contours = []\n",
    "\n",
    "    # Appending all keys in a list\n",
    "    for key,value in contours_dict.items():\n",
    "        arr_keys.append(key)\n",
    "\n",
    "    # Looping through all contours and keeping arr_keys only\n",
    "    for i in range(len(contours)):\n",
    "        for j in range(len(arr_keys)):\n",
    "            if i == arr_keys[j]:\n",
    "                new_contours.append(contours[i])\n",
    "\n",
    "    #return new_contours\n",
    "    return new_contours\n",
    "\n",
    "\n",
    "def do_cheque_contrast_and_find_contours(img, contrast, brightness, dilation_factor, contour_mode, isComplete, thresh_new):\n",
    "    if isComplete == True:\n",
    "        #1 - \n",
    "        alpha = contrast # Contrast control (1.0-3.0)\n",
    "        beta = brightness # Brightness control (0-100)\n",
    "        adjusted = cv2.convertScaleAbs(img, alpha=alpha, beta=beta)\n",
    "\n",
    "        #2 - convert the image to grayscale format\n",
    "        img_gray = cv2.cvtColor(adjusted, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        #3 - apply thresholding\n",
    "        ret, thresh = cv2.threshold(img_gray, 150, 255, cv2.THRESH_OTSU|cv2.THRESH_BINARY_INV)\n",
    "\n",
    "        #4 - Finding rows/col\n",
    "        rect_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (dilation_factor[0],dilation_factor[1]))\n",
    "        dilation = cv2.dilate(thresh, rect_kernel, iterations=1)\n",
    "\n",
    "        #5- Find contours\n",
    "        contours, hierarchy = cv2.findContours(image=dilation, mode=contour_mode, method=cv2.CHAIN_APPROX_NONE)\n",
    "        image_copy = img.copy()\n",
    "        cv2.drawContours(image=image_copy, contours=contours, contourIdx=-1, color=(0, 255, 0), thickness=5, lineType=cv2.LINE_AA)\n",
    "\n",
    "        #6- Cropped contours\n",
    "        arr_contours = []\n",
    "        draw_rectangle_on_img_contours_and_save_them(contours, thresh, arr_contours)\n",
    "\n",
    "        #7- Return contours\n",
    "        return arr_contours\n",
    "    \n",
    "    else:\n",
    "        #4 - Finding rows/col\n",
    "        thresh_new = np.array(thresh_new)\n",
    "        rect_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (dilation_factor[0],dilation_factor[1]))\n",
    "        dilation = cv2.dilate(thresh_new, rect_kernel, iterations=1)\n",
    "\n",
    "        #5- Find contours\n",
    "        contours, hierarchy = cv2.findContours(image=dilation, mode=contour_mode, method=cv2.CHAIN_APPROX_NONE)\n",
    "        image_copy = img.copy()\n",
    "        cv2.drawContours(image=image_copy, contours=contours, contourIdx=-1, color=(0, 255, 0), thickness=5, lineType=cv2.LINE_AA)\n",
    "\n",
    "        #6- Find only desired area contour and sort them left->right\n",
    "        new_contours = []\n",
    "\n",
    "        for cnt in contours:\n",
    "            area = cv2.contourArea(cnt)\n",
    "            if area > 10000 and area <100000:\n",
    "                new_contours.append(cnt)\n",
    "        \n",
    "        contours = new_contours\n",
    "        contours = sorted(contours, key=ret_x_cord_contour, reverse=False)\n",
    "        \n",
    "        #6- Cropped contours\n",
    "        arr_contours = []\n",
    "        draw_rectangle_on_img_contours_and_save_them(contours, thresh_new, arr_contours)\n",
    "\n",
    "        #7- Return contours\n",
    "        return arr_contours\n",
    "    \n",
    "\n",
    "def get_chars_from_word_img(binary_img):\n",
    "    #1- make copy\n",
    "    img = binary_img.copy()\n",
    "\n",
    "    #2- Do padding\n",
    "    img = cv2.copyMakeBorder(np.array(img), 30, 30, 0, 0, cv2.BORDER_CONSTANT, None, value=(0,0,0))\n",
    "\n",
    "    #3- Find contours\n",
    "    contours, hierarchy = cv2.findContours(image=img, mode=cv2.RETR_EXTERNAL, method=cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "    #4- Sort contours\n",
    "    contours = sorted(contours, key=ret_x_cord_contour, reverse=False)\n",
    "\n",
    "    #5- Crop contours\n",
    "    arr = []\n",
    "    draw_rectangle_on_img_contours_and_croppping_them(contours,img.copy(),arr)\n",
    "\n",
    "    return arr\n",
    "\n",
    "                \n",
    "def get_cheque_right_section_rows(right_img):\n",
    "    #1- Do contrast\n",
    "    alpha = 1.5 # Contrast control (1.0-3.0)\n",
    "    beta = 90 # Brightness control (0-100)\n",
    "    adjusted = cv2.convertScaleAbs(right_img.copy(), alpha=alpha, beta=beta)\n",
    "    \n",
    "    #2- convert the image to grayscale format\n",
    "    img_gray = cv2.cvtColor(adjusted, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    #3- apply thresholding\n",
    "    ret, thresh = cv2.threshold(img_gray, 150, 255, cv2.THRESH_OTSU|cv2.THRESH_BINARY_INV)\n",
    "    \n",
    "    #4-  Finding rows\n",
    "    rect_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (500,10))\n",
    "    dilation = cv2.dilate(thresh, rect_kernel, iterations=1)\n",
    "    \n",
    "    #5- detect the contours\n",
    "    contours, hierarchy = cv2.findContours(image=dilation, mode=cv2.RETR_EXTERNAL, method=cv2.CHAIN_APPROX_NONE)\n",
    "    #print(\"==>\",type(contours))\n",
    "    print(contours[0])\n",
    "    if len(contours)>2:\n",
    "        del contours[0]\n",
    "\n",
    "    #6- Crop detected contours\n",
    "    arr = []\n",
    "    draw_rectangle_on_img_contours_and_save_them(contours, right_img.copy(), arr)\n",
    "    return arr\n",
    "\n",
    "\n",
    "def get_date_contours(date_img):\n",
    "    #1- Do contrast\n",
    "    alpha = 3.0 # Contrast control (1.0-3.0)\n",
    "    beta = 100 # Brightness control (0-100)\n",
    "    adjusted = cv2.convertScaleAbs(date_img, alpha=alpha, beta=beta)\n",
    "\n",
    "    #2- convert the image to grayscale format\n",
    "    img_gray = cv2.cvtColor(adjusted, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    #3- apply thresholding\n",
    "    ret, thresh = cv2.threshold(img_gray, 150, 255, cv2.THRESH_OTSU|cv2.THRESH_BINARY_INV)\n",
    "\n",
    "    #4- detect the contours\n",
    "    contours, hierarchy = cv2.findContours(image=thresh, mode=cv2.RETR_EXTERNAL, method=cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "    #5- Remove Extraneous contours and sort contours\n",
    "    #contours_to_keep_dict = get_all_childs_of_parent(1,hierarchy)\n",
    "    #contours = remove_extraneous_contours_childs(contours,contours_to_keep_dict)\n",
    "    #contours = sorted(contours, key=ret_x_cord_contour, reverse=False)\n",
    "\n",
    "    #6- Crop detected contours\n",
    "    arr = []\n",
    "    draw_rectangle_on_img_contours_and_save_them(contours, thresh.copy(), arr)\n",
    "    return arr\n",
    "\n",
    "\n",
    "def get_amount_contours(amount_img):\n",
    "    #1 - \n",
    "    y = amount_img.height #Height\n",
    "    x = amount_img.width #Width\n",
    "\n",
    "    #2- Crop\n",
    "    amount_img = np.array(amount_img)\n",
    "    amount_img = amount_img[40:y-15, 350:x-120]\n",
    "\n",
    "    #3\n",
    "    alpha = 3.0 # Contrast control (1.0-3.0)\n",
    "    beta = 100 # Brightness control (0-100)\n",
    "    adjusted = cv2.convertScaleAbs(amount_img, alpha=alpha, beta=beta)\n",
    "\n",
    "    #4 - Grayscale\n",
    "    img_gray = cv2.cvtColor(adjusted, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    #5- apply thresholding\n",
    "    ret, thresh = cv2.threshold(img_gray, 150, 255, cv2.THRESH_OTSU|cv2.THRESH_BINARY_INV)\n",
    "\n",
    "    #6- detect the contours\n",
    "    contours, hierarchy = cv2.findContours(image=thresh, mode=cv2.RETR_EXTERNAL, method=cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "    #7- Remove Extraneous contours and sort contours\n",
    "    contours = remove_contours_beyond_desired_area_range(contours,1000)\n",
    "    contours = sorted(contours, key=ret_x_cord_contour, reverse=False)\n",
    "\n",
    "    #8- Crop detected contours\n",
    "    arr = []\n",
    "    draw_rectangle_on_img_contours_and_croppping_them(contours,thresh.copy(),arr)\n",
    "    return arr\n",
    "\n",
    "def resizing_cropped_img_to_28_by_28(arr_cropped_images, arr_new):\n",
    "    \n",
    "    for i in range(len(arr_cropped_images)):\n",
    "        # Step:6 Calculating new size\n",
    "        img_height = arr_cropped_images[i].height\n",
    "        img_width = arr_cropped_images[i].width\n",
    "\n",
    "        #print(img_height,img_width)\n",
    "\n",
    "        # Tall and narrow image\n",
    "        if img_height > img_width:\n",
    "            img_height = 20\n",
    "            scale_factor = arr_cropped_images[i].height / img_height  #old_height/new_height\n",
    "            img_width = int(img_width/scale_factor)\n",
    "\n",
    "        # Short and narrow image\n",
    "        else:\n",
    "            img_width = 20\n",
    "            scale_factor = arr_cropped_images[i].width / img_width  #old_widht/new_width\n",
    "            img_height = int(img_height/scale_factor)\n",
    "\n",
    "        new_size = (img_width,img_height)\n",
    "        img_resized = cv2.resize(np.array(arr_cropped_images[i]),new_size,0,0,cv2.INTER_AREA) #src,dest,dsize,0,0,cv2.INTER_AREA\n",
    "\n",
    "        LEFT = math.ceil(4+(20-img_width)/2)\n",
    "        RIGHT = math.floor(4+(20-img_width)/2)\n",
    "        TOP = math.ceil(4+(20-img_height)/2)\n",
    "        BOTTOM = math.ceil(4+(20-img_height)/2)\n",
    "\n",
    "        img_28_by_28 = cv2.copyMakeBorder(img_resized, TOP, BOTTOM, LEFT, RIGHT, cv2.BORDER_CONSTANT, None, (0,0,0))\n",
    "        arr_new.append(img_28_by_28)\n",
    "        #plt.imshow(img_28_by_28)\n",
    "        #plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognize_cheque_details(image):\n",
    "    global ARR_LEFT_SECTION_CONTOURS\n",
    "    global ARR_PAYEE_CONTOURS\n",
    "    global ARR_PAYEE_WORDS\n",
    "    global ARR_PAYEE_FIRST_NAME\n",
    "    global ARR_PAYEE_MIDDLE_NAME\n",
    "    global ARR_PAYEE_LAST_NAME\n",
    "\n",
    "    global ARR_RIGHT_SECTION_CONTOURS\n",
    "    global ARR_DATE_CONTOURS\n",
    "    global ARR_AMOUNT_CONTOURS\n",
    "    \n",
    "    first_name_prediction = \"\"\n",
    "    middle_name_prediction = \"\"\n",
    "    last_name_prediction = \"\"\n",
    "    # ------------------------------------------------\n",
    "    # STEP 1: SPLIT IMAGE BY 30 AND 70 RATIO\n",
    "    # ------------------------------------------------\n",
    "    img = cv2.imread(image)\n",
    "    \n",
    "    y = img.shape[0] #Height\n",
    "    x = img.shape[1] #Width\n",
    "    \n",
    "    crop_ratio = int(x/3) # 100%-30% = 70%\n",
    "    \n",
    "    # Left section 70%\n",
    "    IMG_LEFT_CROP = img[0:y, 0:x-crop_ratio] #[height, width]\n",
    "    \n",
    "    # Right section 30%\n",
    "    IMG_RIGHT_CROP = img[0:y, x-crop_ratio:x] #[height, width] \n",
    "    \n",
    "    \n",
    "    # ------------------------------------------------\n",
    "    # STEP 2: EXTRACT ONLY DESIRED SECTION FROM LEFT\n",
    "    #         CROP IMAGE\n",
    "    # ------------------------------------------------\n",
    "    # Vertically 20-25% above and the below area is of our no use. Discard it.\n",
    "    y = IMG_LEFT_CROP.shape[0] #Height\n",
    "    x = IMG_LEFT_CROP.shape[1] #Width\n",
    "    \n",
    "    crop_ratio = int(y/1.35) # 100%-13.5% = 86.5%\n",
    "    IMG_LEFT_CROP = IMG_LEFT_CROP[y-crop_ratio:y-(y-crop_ratio), 0:x] #[height, width] => [362,]\n",
    "    \n",
    "    # Cropping more from bottom\n",
    "    image_copy = IMG_LEFT_CROP.copy()\n",
    "    IMG_LEFT_CROP = image_copy[0:y-150,0:x]\n",
    "    \n",
    "    # ------------------------------------------------\n",
    "    # STEP 2.1: FIND CONTOURS ON LEFT SECTION\n",
    "    # ------------------------------------------------\n",
    "    ARR_LEFT_SECTION_CONTOURS = do_cheque_contrast_and_find_contours(IMG_LEFT_CROP, 3, 150, (500,10), cv2.RETR_EXTERNAL, True, None)\n",
    "    ARR_LEFT_SECTION_CONTOURS.reverse()\n",
    "    \n",
    "    # ------------------------------------------------\n",
    "    # STEP 2.2: EXTRACTING PAYEE NAME\n",
    "    # ------------------------------------------------\n",
    "    ARR_PAYEE_CONTOURS.clear()\n",
    "    ARR_PAYEE_CONTOURS = do_cheque_contrast_and_find_contours(IMG_LEFT_CROP, 3, 150, (70,1), cv2.RETR_LIST, False, ARR_LEFT_SECTION_CONTOURS[0].copy())\n",
    "    \n",
    "    if len(ARR_PAYEE_CONTOURS) == 1:\n",
    "        ARR_PAYEE_FIRST_NAME.clear()\n",
    "        ARR_PAYEE_FIRST_NAME = get_chars_from_word_img(ARR_PAYEE_CONTOURS[0])\n",
    "    elif len(ARR_PAYEE_CONTOURS) == 2:\n",
    "        ARR_PAYEE_FIRST_NAME.clear()\n",
    "        ARR_PAYEE_FIRST_NAME = get_chars_from_word_img(ARR_PAYEE_CONTOURS[0])\n",
    "        ARR_PAYEE_LAST_NAME.clear()\n",
    "        ARR_PAYEE_LAST_NAME = get_chars_from_word_img(ARR_PAYEE_CONTOURS[1])\n",
    "    elif len(ARR_PAYEE_CONTOURS) == 3:\n",
    "        ARR_PAYEE_FIRST_NAME.clear()\n",
    "        ARR_PAYEE_FIRST_NAME = get_chars_from_word_img(ARR_PAYEE_CONTOURS[0])\n",
    "        ARR_PAYEE_MIDDLE_NAME.clear()\n",
    "        ARR_PAYEE_MIDDLE_NAME = get_chars_from_word_img(ARR_PAYEE_CONTOURS[1])\n",
    "        ARR_PAYEE_LAST_NAME.clear()\n",
    "        ARR_PAYEE_LAST_NAME = get_chars_from_word_img(ARR_PAYEE_CONTOURS[2])\n",
    "    #else:\n",
    "        # Do nothing\n",
    "        \n",
    "     \n",
    "    # ------------------------------------------------\n",
    "    # STEP 3: EXTRACT ONLY DESIRED SECTION FROM RIGHT\n",
    "    #         CROP IMAGE\n",
    "    # -----------------------------------------------\n",
    "    y = IMG_RIGHT_CROP.shape[0] #Height\n",
    "    x = IMG_RIGHT_CROP.shape[1] #Width\n",
    "    \n",
    "    bottom_crop_ratio = int(y/2.5) # 100%-25% = 75%\n",
    "    top_crop_ratio = int(y/6.8) # 100%-68% = 30%\n",
    "\n",
    "    IMG_RIGHT_CROP = IMG_RIGHT_CROP[top_crop_ratio:y-bottom_crop_ratio, 0:x] #[height, width] => [362,]\n",
    "    ARR_RIGHT_SECTION_CONTOURS = get_cheque_right_section_rows(IMG_RIGHT_CROP)\n",
    "    \n",
    "    \n",
    "    if len(ARR_RIGHT_SECTION_CONTOURS) == 2:\n",
    "        ARR_RIGHT_SECTION_CONTOURS.reverse()\n",
    "    \n",
    "        # ------------------------------------------------\n",
    "        # STEP 3.1: FIND DATE CONTOURS\n",
    "        # -----------------------------------------------\n",
    "        date_img = np.array(ARR_RIGHT_SECTION_CONTOURS[0])\n",
    "        ARR_DATE_CONTOURS = get_date_contours(date_img)\n",
    "        ARR_DATE_CONTOURS.reverse()\n",
    "        if len(ARR_DATE_CONTOURS) > 8:\n",
    "            del ARR_DATE_CONTOURS[0]\n",
    "            \n",
    "        # ------------------------------------------------\n",
    "        # STEP 3.2: FIND AMOUNT CONTOURS\n",
    "        # -----------------------------------------------\n",
    "            \n",
    "        y = ARR_RIGHT_SECTION_CONTOURS[1].height #Height\n",
    "        x = ARR_RIGHT_SECTION_CONTOURS[1].width #Width\n",
    "        \n",
    "        image_copy = ARR_RIGHT_SECTION_CONTOURS[1].copy()\n",
    "        image_copy = np.array(image_copy)\n",
    "        \n",
    "        crop_amount_in_words = image_copy[40:y-15, 350:x-120]\n",
    "        \n",
    "        ARR_AMOUNT_CONTOURS = get_amount_contours(ARR_RIGHT_SECTION_CONTOURS[1])\n",
    "        \n",
    "    # ------------------------------------------------\n",
    "    # STEP 4: CONVERT ALL EXTRACTED CONTOURS TO\n",
    "    #         28X28\n",
    "    # -----------------------------------------------\n",
    "    arr_amount_28x28 = []\n",
    "    resizing_cropped_img_to_28_by_28(ARR_AMOUNT_CONTOURS, arr_amount_28x28)\n",
    "    \n",
    "    arr_date_28x28 = []\n",
    "    resizing_cropped_img_to_28_by_28(ARR_DATE_CONTOURS, arr_date_28x28)\n",
    "    \n",
    "    arr_payee_first_name_28x28 = []\n",
    "    resizing_cropped_img_to_28_by_28(ARR_PAYEE_FIRST_NAME, arr_payee_first_name_28x28)\n",
    "    \n",
    "    arr_payee_middle_name_28x28 = []\n",
    "    resizing_cropped_img_to_28_by_28(ARR_PAYEE_MIDDLE_NAME, arr_payee_middle_name_28x28)\n",
    "    \n",
    "    arr_payee_last_name_28x28 = []\n",
    "    resizing_cropped_img_to_28_by_28(ARR_PAYEE_LAST_NAME, arr_payee_last_name_28x28)\n",
    "    \n",
    "    # ------------------------------------------------\n",
    "    # STEP 5: FLATTEN ALL 28X28 IMAGES\n",
    "    # ------------------------------------------------\n",
    "    x_arr_amount = []\n",
    "    for i in range(len(arr_amount_28x28)):\n",
    "        x_arr_amount.append(arr_amount_28x28[i].ravel())\n",
    "        \n",
    "    x_arr_date = []\n",
    "    for i in range(len(arr_date_28x28)):\n",
    "        x_arr_date.append(arr_date_28x28[i].ravel())\n",
    "        \n",
    "    x_arr_first_name = []\n",
    "    for i in range(len(arr_payee_first_name_28x28)):\n",
    "        x_arr_first_name.append(arr_payee_first_name_28x28[i].ravel())\n",
    "        \n",
    "    x_arr_middle_name = []\n",
    "    for i in range(len(arr_payee_middle_name_28x28)):\n",
    "        x_arr_middle_name.append(arr_payee_middle_name_28x28[i].ravel())\n",
    "        \n",
    "    x_arr_last_name = []\n",
    "    for i in range(len(arr_payee_last_name_28x28)):\n",
    "        x_arr_last_name.append(arr_payee_last_name_28x28[i].ravel())\n",
    "        \n",
    "    # ------------------------------------------------\n",
    "    # STEP 6: LOAD DIGITS MODEL AND CREATE SESSION\n",
    "    # ------------------------------------------------\n",
    "    # Create a graph obj placeholder\n",
    "    graph = tf.Graph()\n",
    "\n",
    "    # Creating a sess obj and linking session and the graph\n",
    "    sess = tf.compat.v1.Session(graph=graph)\n",
    "\n",
    "    # Loading the Model\n",
    "    load(sess=sess, tags=[tag_constants.SERVING], export_dir='SavedModel')\n",
    "    \n",
    "    # ------------------------------------------------\n",
    "    # STEP 7: MAKING DIGITS PREDICTIONS\n",
    "    # ------------------------------------------------\n",
    "    # Return the `Tensor` with the given `name` and index=0 result\n",
    "    X = graph.get_tensor_by_name('X:0')\n",
    "\n",
    "    # Get hold of the tensor that will hold the predictions from the graph. Store these under y_pred\n",
    "    y_pred = graph.get_tensor_by_name('accuracy_calc/prediction:0')\n",
    "\n",
    "    # fetches = y_pred(the output we are after)\n",
    "    amount_prediction = sess.run(fetches=y_pred, feed_dict={X:x_arr_amount})\n",
    "    date_prediction = sess.run(fetches=y_pred, feed_dict={X:x_arr_date})\n",
    "    \n",
    "    # ------------------------------------------------\n",
    "    # STEP 8: LOAD ALPHABETS MODEL AND CREATE SESSION\n",
    "    # ------------------------------------------------\n",
    "    # Create a graph obj placeholder\n",
    "    graph = tf.Graph()\n",
    "\n",
    "    # Creating a sess obj and linking session and the graph\n",
    "    sess = tf.compat.v1.Session(graph=graph)\n",
    "\n",
    "    # Loading the Model\n",
    "    load(sess=sess, tags=[tag_constants.SERVING], export_dir='SavedModel_Alpha')\n",
    "    \n",
    "    # ------------------------------------------------\n",
    "    # STEP 9: MAKING DIGITS PREDICTIONS\n",
    "    # ------------------------------------------------\n",
    "    # Return the `Tensor` with the given `name` and index=0 result\n",
    "    X = graph.get_tensor_by_name('X:0')\n",
    "\n",
    "    # Get hold of the tensor that will hold the predictions from the graph. Store these under y_pred\n",
    "    y_pred = graph.get_tensor_by_name('accuracy_calc/prediction:0')\n",
    "\n",
    "    # fetches = y_pred(the output we are after)\n",
    "    if len(x_arr_first_name) > 0:\n",
    "        first_name_prediction = sess.run(fetches=y_pred, feed_dict={X:x_arr_first_name})\n",
    "    if len(x_arr_middle_name) > 0:\n",
    "        middle_name_prediction = sess.run(fetches=y_pred, feed_dict={X:x_arr_middle_name})\n",
    "    if len(x_arr_last_name) > 0:\n",
    "        last_name_prediction = sess.run(fetches=y_pred, feed_dict={X:x_arr_last_name})\n",
    "        \n",
    "    # ------------------------------------------------\n",
    "    # STEP 10: DECODING ALPHABETS PREDICTIONS\n",
    "    # ------------------------------------------------\n",
    "    arr_predicted_first_name = []\n",
    "    arr_predicted_middle_name = []\n",
    "    arr_predicted_last_name = []\n",
    "    \n",
    "    for i in range(len(first_name_prediction)):\n",
    "        for key,value in ALPHABETS.items():\n",
    "            if first_name_prediction[i] == key:\n",
    "                arr_predicted_first_name.append(value)\n",
    "                \n",
    "    for i in range(len(middle_name_prediction)):\n",
    "        for key,value in ALPHABETS.items():\n",
    "            if middle_name_prediction[i] == key:\n",
    "                arr_predicted_middle_name.append(value)\n",
    "                \n",
    "    for i in range(len(last_name_prediction)):\n",
    "        for key,value in ALPHABETS.items():\n",
    "            if last_name_prediction[i] == key:\n",
    "                arr_predicted_last_name.append(value)\n",
    "                \n",
    "    # ------------------------------------------------\n",
    "    # STEP 11: CONVERTING ARR INTO STRING\n",
    "    # ------------------------------------------------\n",
    "    amount = ''.join(map(str,amount_prediction))\n",
    "    amount = 'Rs.' + amount\n",
    "    date = ''.join(map(str,date_prediction))\n",
    "    payee_fn = ''.join(map(str,arr_predicted_first_name))\n",
    "    payee_mn = ''.join(map(str,arr_predicted_middle_name))\n",
    "    payee_ln = ''.join(map(str,arr_predicted_last_name))\n",
    "    \n",
    "    new_date = ''\n",
    "    for i in range(len(date)):\n",
    "        if i == 2 or i == 4:\n",
    "            new_date += '/' + date[i]\n",
    "        else:\n",
    "            new_date += date[i]\n",
    "    \n",
    "    print(amount)\n",
    "    print(new_date)\n",
    "    print(payee_fn)\n",
    "    print(payee_mn)\n",
    "    print(payee_ln)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[503 619]]\n",
      "\n",
      " [[502 620]]\n",
      "\n",
      " [[501 620]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[506 619]]\n",
      "\n",
      " [[505 619]]\n",
      "\n",
      " [[504 619]]]\n",
      "WARNING:tensorflow:From <ipython-input-4-b8fd26cfe32a>:171: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.loader.load or tf.compat.v1.saved_model.load. There will be a new function for importing SavedModels in Tensorflow 2.0.\n",
      "INFO:tensorflow:Restoring parameters from SavedModel/variables/variables\n",
      "INFO:tensorflow:Restoring parameters from SavedModel_Alpha/variables/variables\n",
      "Rs.430228\n",
      "31/21/1988\n",
      "EAYQUE\n",
      "\n",
      "ALY\n"
     ]
    }
   ],
   "source": [
    "recognize_cheque_details(SAMPLE_IMAGE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
